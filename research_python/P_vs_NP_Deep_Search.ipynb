{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# P vs NP: Deep Search Workspace\n",
                "\n",
                "This notebook runs the 'Frozen Backbone' search loop. It generates 3-SAT instances, identifies their backbone using a DPLL solver, and trains a GNN to predict the backbone.\n",
                "\n",
                "**Goal:** Find a model with >95% accuracy, which would indicate a polynomial-time solution to identifying hard SAT structures."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Dependencies\n",
                "!pip install torch numpy networkx"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Setup Project Structure\n",
                "import os\n",
                "os.makedirs('src', exist_ok=True)\n",
                "os.makedirs('data', exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile src/sat_generator.py\n",
                "import random\n",
                "import numpy as np\n",
                "\n",
                "class SatGenerator:\n",
                "    @staticmethod\n",
                "    def generate_3sat(n_vars, alpha=4.26):\n",
                "        n_clauses = int(round(n_vars * alpha))\n",
                "        clauses = []\n",
                "        for _ in range(n_clauses):\n",
                "            vars_idx = random.sample(range(1, n_vars + 1), 3)\n",
                "            clause = [v if random.random() > 0.5 else -v for v in vars_idx]\n",
                "            clauses.append(clause)\n",
                "        return clauses, n_vars"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile src/dpll_solver.py\n",
                "import sys\n",
                "from collections import Counter\n",
                "sys.setrecursionlimit(50000)\n",
                "\n",
                "class DpllSolver:\n",
                "    def __init__(self):\n",
                "        self.steps = 0\n",
                "        self.backtracks = 0\n",
                "\n",
                "    def solve(self, clauses, n_vars):\n",
                "        self.steps = 0\n",
                "        self.backtracks = 0\n",
                "        if not clauses: return True, {}\n",
                "        return self._dpll(clauses, {})\n",
                "\n",
                "    def _dpll(self, clauses, assignment):\n",
                "        self.steps += 1\n",
                "        if not clauses: return True, assignment\n",
                "        for c in clauses:\n",
                "            if not c: return False, None\n",
                "\n",
                "        # Unit Prop\n",
                "        while True:\n",
                "            unit_lit = None\n",
                "            for c in clauses:\n",
                "                if len(c) == 1:\n",
                "                    unit_lit = c[0]\n",
                "                    break\n",
                "            if unit_lit is None: break\n",
                "            assignment[abs(unit_lit)] = (unit_lit > 0)\n",
                "            clauses = self._simplify(clauses, unit_lit)\n",
                "            if not clauses: return True, assignment\n",
                "            for c in clauses:\n",
                "                if not c: return False, None\n",
                "\n",
                "        # Heuristic\n",
                "        counter = Counter()\n",
                "        for c in clauses:\n",
                "            for lit in c: counter[lit] += 1\n",
                "        if not counter: return True, assignment\n",
                "\n",
                "        best_lit, _ = counter.most_common(1)[0]\n",
                "        new_assign = assignment.copy()\n",
                "        new_assign[abs(best_lit)] = (best_lit > 0)\n",
                "        res, final_assign = self._dpll(self._simplify(clauses, best_lit), new_assign)\n",
                "        if res: return True, final_assign\n",
                "\n",
                "        self.backtracks += 1\n",
                "        new_assign = assignment.copy()\n",
                "        new_assign[abs(best_lit)] = (best_lit < 0)\n",
                "        return self._dpll(self._simplify(clauses, -best_lit), new_assign)\n",
                "\n",
                "    def _simplify(self, clauses, literal):\n",
                "        new_clauses = []\n",
                "        for c in clauses:\n",
                "            if literal in c: continue\n",
                "            if -literal in c:\n",
                "                new_c = [l for l in c if l != -literal]\n",
                "                new_clauses.append(new_c)\n",
                "            else:\n",
                "                new_clauses.append(c)\n",
                "        return new_clauses"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile src/backbone_finder.py\n",
                "from .dpll_solver import DpllSolver\n",
                "\n",
                "class BackboneFinder:\n",
                "    def __init__(self):\n",
                "        self.solver = DpllSolver()\n",
                "    \n",
                "    def find_backbone(self, clauses, n_vars):\n",
                "        satisfiable, first_assignment = self.solver.solve(clauses, n_vars)\n",
                "        if not satisfiable: return {}, False\n",
                "        \n",
                "        backbone = {}\n",
                "        for var in range(1, n_vars + 1):\n",
                "            if var not in first_assignment: continue\n",
                "            val = first_assignment[var]\n",
                "            # Try to flip\n",
                "            negated_unit = -var if val else var\n",
                "            test_clauses = clauses + [[negated_unit]]\n",
                "            is_flippable, _ = self.solver.solve(test_clauses, n_vars)\n",
                "            if not is_flippable:\n",
                "                backbone[var] = val\n",
                "        return backbone, True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile src/gnn_model.py\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "class BackboneMPNN(nn.Module):\n",
                "    def __init__(self, hidden_dim=64, num_layers=4):\n",
                "        super().__init__()\n",
                "        self.hidden_dim = hidden_dim\n",
                "        self.num_layers = num_layers\n",
                "        self.type_embed = nn.Embedding(2, hidden_dim)\n",
                "        self.msg_v2c = nn.Sequential(nn.Linear(hidden_dim * 2 + 1, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, hidden_dim))\n",
                "        self.msg_c2v = nn.Sequential(nn.Linear(hidden_dim * 2 + 1, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, hidden_dim))\n",
                "        self.update_var = nn.GRUCell(hidden_dim, hidden_dim)\n",
                "        self.update_clause = nn.GRUCell(hidden_dim, hidden_dim)\n",
                "        self.projection_head = nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 1))\n",
                "\n",
                "    def forward(self, n_vars, clauses, device='cpu'):\n",
                "        num_clauses = len(clauses)\n",
                "        num_nodes = n_vars + num_clauses\n",
                "        node_types = torch.zeros(num_nodes, dtype=torch.long, device=device)\n",
                "        node_types[n_vars:] = 1 \n",
                "        h = self.type_embed(node_types)\n",
                "        \n",
                "        v_indices = []\n",
                "        c_indices = []\n",
                "        signs = []\n",
                "        for c_idx, clause in enumerate(clauses):\n",
                "            c_node = n_vars + c_idx\n",
                "            for lit in clause:\n",
                "                v_indices.append(abs(lit) - 1)\n",
                "                c_indices.append(c_node)\n",
                "                signs.append(1.0 if lit > 0 else -1.0)\n",
                "        \n",
                "        v_tensor = torch.tensor(v_indices, dtype=torch.long, device=device)\n",
                "        c_tensor = torch.tensor(c_indices, dtype=torch.long, device=device)\n",
                "        s_tensor = torch.tensor(signs, dtype=torch.float, device=device).unsqueeze(1)\n",
                "        \n",
                "        for _ in range(self.num_layers):\n",
                "            h_v = h[v_tensor]\n",
                "            h_c_target = h[c_tensor]\n",
                "            msg = self.msg_v2c(torch.cat([h_v, h_c_target, s_tensor], dim=1))\n",
                "            agg_c = torch.zeros(num_nodes, self.hidden_dim, device=device)\n",
                "            agg_c.index_add_(0, c_tensor, msg)\n",
                "            h_clauses_new = self.update_clause(agg_c[n_vars:], h[n_vars:])\n",
                "            \n",
                "            h_vars_current = h[:n_vars]\n",
                "            h = torch.cat([h_vars_current, h_clauses_new], dim=0)\n",
                "            \n",
                "            h_c = h[c_tensor]\n",
                "            h_v_target = h[v_tensor]\n",
                "            msg = self.msg_c2v(torch.cat([h_c, h_v_target, s_tensor], dim=1))\n",
                "            agg_v = torch.zeros(num_nodes, self.hidden_dim, device=device)\n",
                "            agg_v.index_add_(0, v_tensor, msg)\n",
                "            h_vars_new = self.update_var(agg_v[:n_vars], h[:n_vars])\n",
                "            \n",
                "            h_clauses_current = h[n_vars:]\n",
                "            h = torch.cat([h_vars_new, h_clauses_current], dim=0)\n",
                "            \n",
                "        return torch.sigmoid(self.projection_head(h[:n_vars])).squeeze(1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Run the Automated Search Loop\n",
                "import torch\n",
                "import torch.optim as optim\n",
                "import torch.nn as nn\n",
                "from src.sat_generator import SatGenerator\n",
                "from src.backbone_finder import BackboneFinder\n",
                "from src.gnn_model import BackboneMPNN\n",
                "\n",
                "def generate_batch(num_samples, n_vars, alpha=4.26):\n",
                "    finder = BackboneFinder()\n",
                "    samples = []\n",
                "    count = 0\n",
                "    attempts = 0\n",
                "    while count < num_samples:\n",
                "        attempts += 1\n",
                "        clauses, _ = SatGenerator.generate_3sat(n_vars, alpha)\n",
                "        # Limit N_vars for quick testing in notebook\n",
                "        backbone, sat = finder.find_backbone(clauses, n_vars)\n",
                "        if not sat: continue\n",
                "        \n",
                "        labels = []\n",
                "        backbone_set = set(backbone.keys())\n",
                "        for v in range(1, n_vars+1):\n",
                "            labels.append(1.0 if v in backbone_set else 0.0)\n",
                "            \n",
                "        samples.append((n_vars, clauses, torch.tensor(labels, dtype=torch.float)))\n",
                "        count += 1\n",
                "    return samples\n",
                "\n",
                "def search_loop():\n",
                "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "    print(f\"Using device: {device}\")\n",
                "    \n",
                "    model = BackboneMPNN(hidden_dim=64, num_layers=4).to(device)\n",
                "    optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
                "    criterion = nn.BCELoss()\n",
                "    \n",
                "    cycle = 0\n",
                "    best_acc = 0.0\n",
                "    \n",
                "    while True:\n",
                "        cycle += 1\n",
                "        print(f\"\\n--- CYCLE {cycle} ---\")\n",
                "        print(\"Generating data...\")\n",
                "        data = generate_batch(num_samples=20, n_vars=30)\n",
                "        \n",
                "        train_data = []\n",
                "        for n, c, l in data:\n",
                "            train_data.append((n, c, l.to(device)))\n",
                "            \n",
                "        split = int(0.8 * len(train_data))\n",
                "        train_set = train_data[:split]\n",
                "        val_set = train_data[split:]\n",
                "        \n",
                "        print(\"Training...\")\n",
                "        model.train()\n",
                "        for epoch in range(15):\n",
                "            total_loss = 0\n",
                "            for n, c, l in train_set:\n",
                "                optimizer.zero_grad()\n",
                "                preds = model(n, c, device)\n",
                "                loss = criterion(preds, l)\n",
                "                loss.backward()\n",
                "                optimizer.step()\n",
                "                total_loss += loss.item()\n",
                "        \n",
                "        model.eval()\n",
                "        total_corr = 0\n",
                "        total_nodes = 0\n",
                "        with torch.no_grad():\n",
                "            for n, c, l in val_set:\n",
                "                preds = model(n, c, device)\n",
                "                bin_preds = (preds > 0.5).float()\n",
                "                total_corr += (bin_preds == l).sum().item()\n",
                "                total_nodes += n\n",
                "        \n",
                "        acc = (total_corr / total_nodes) * 100 if total_nodes > 0 else 0\n",
                "        print(f\"Validation Accuracy: {acc:.2f}%\")\n",
                "        \n",
                "        if acc > best_acc:\n",
                "            best_acc = acc\n",
                "            print(f\"New Best! {best_acc:.2f}%\")\n",
                "            \n",
                "search_loop()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}